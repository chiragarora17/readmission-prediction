{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df =  pd.read_csv('dataCategorizedNew.csv',skiprows=1, header=None,dtype='float')\n",
    "dataFrameX = df.sample(frac=1).reset_index(drop=True)\n",
    "dataFrameY = dataFrameX[dataFrameX.columns[len(dataFrameX.columns)-1]]\n",
    "dataFrameX.drop(dataFrameX.columns[len(dataFrameX.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataFrameX, dataFrameY, test_size=0.3) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Following different SVM classifier are used to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM liear classifier\n",
    "\n",
    "classifier1 =svm.LinearSVC()\n",
    "classifier1.fit(x_train, y_train)\n",
    "y_pred=classifier1.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "classifier2 =svm.LinearSVC(C=0.5)\n",
    "classifier2.fit(x_train, y_train)\n",
    "y_pred=classifier2.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier3 =svm.LinearSVC(C=0.25)\n",
    "classifier3.fit(x_train, y_train)\n",
    "y_pred=classifier3.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier4 =svm.LinearSVC(C=0.3)\n",
    "classifier4.fit(x_train, y_train)\n",
    "y_pred=classifier4.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier6 =svm.LinearSVC(C=0.2)\n",
    "classifier6.fit(x_train, y_train)\n",
    "y_pred=classifier6.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier7 =svm.LinearSVC(C=1.6)\n",
    "classifier7.fit(x_train, y_train)\n",
    "y_pred=classifier7.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier7 =svm.LinearSVC(C=2.0)\n",
    "classifier7.fit(x_train, y_train)\n",
    "y_pred=classifier7.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier5 =svm.NuSVC(nu=0.5,kernel='sigmoid')\n",
    "classifier5.fit(x_train, y_train)\n",
    "y_pred=classifier5.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier9 =svm.NuSVC(nu=0.25,kernel='rbf')\n",
    "classifier9.fit(x_train, y_train)\n",
    "y_pred=classifier9.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clfB = BernoulliNB()\n",
    "clfB.fit(x_train, y_train)\n",
    "y_pred = clfB.predict(x_test)\n",
    "print(\"F1-score on validation data:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h= dataFrameY\n",
    "sorted(h)\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.5: 0.32647987202168227, 1.0: 0.48973739953595857, 1.2: 0.43941818996637416, 0.2: 0.31813024246581362, 0.4: 0.49897006937844463, 0.8: 0.54462248278020264, 0.3: 0.51324379154870492, 1.6: 0.34286376129684204, 0.6: 0.4614671112664287, 0.1: 0.36654655854494872, 0.9: 0.46360464675885393, 1.7: 0.5683878552076399, 1.4: 0.45637520921412528, 1.3: 0.36658280637725826, 0.7: 0.40785526433754193, 1.9: 0.52168500351383684, 1.1: 0.53199142837187208, 1.8: 0.49098274326746644, 1.5: 0.52051698231810617}\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "scoreDict= {}\n",
    "for i in range(1,20,1):\n",
    "    i=i/10.0\n",
    "    classifier =svm.LinearSVC(C=i)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred=classifier.predict(x_test)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
    "    scoreDict[i]=f1_score\n",
    "\n",
    "\n",
    "print scoreDict\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "max(scoreDict.iteritems(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
